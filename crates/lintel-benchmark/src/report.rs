use std::io::Write;
use std::path::Path;

use anyhow::Result;

use crate::runner::Stats;

pub const WARMUP_RUNS: usize = 2;
pub const MIN_RUNS: usize = 10;

struct BenchResult {
    label: String,
    stats: Stats,
}

struct BenchSection {
    title: String,
    results: Vec<BenchResult>,
}

pub struct Report {
    lintel_version: String,
    sections: Vec<BenchSection>,
}

impl Report {
    pub fn new(lintel_version: &str) -> Self {
        Self {
            lintel_version: lintel_version.to_string(),
            sections: Vec::new(),
        }
    }

    pub fn section(&mut self, title: &str) {
        println!();
        println!("=== {title} ===");
        println!();
        self.sections.push(BenchSection {
            title: title.to_string(),
            results: Vec::new(),
        });
    }

    pub fn add(&mut self, label: &str, stats: Stats) {
        println!("  {label:<50} {stats}");
        if let Some(section) = self.sections.last_mut() {
            section.results.push(BenchResult {
                label: label.to_string(),
                stats,
            });
        }
    }

    #[allow(clippy::too_many_lines)]
    pub fn write_markdown(&self, path: &Path) -> Result<()> {
        let mut f = std::fs::File::create(path)?;

        writeln!(f, "# Lintel Benchmarks")?;
        writeln!(f)?;
        writeln!(
            f,
            "> Auto-generated by `cargo run --release --package lintel-benchmark -- run`. Do not edit."
        )?;
        writeln!(f)?;
        writeln!(f, "- **lintel version**: {}", self.lintel_version)?;
        writeln!(
            f,
            "- **date**: {}",
            chrono::Local::now().format("%Y-%m-%d %H:%M:%S")
        )?;
        writeln!(f, "- **platform**: {}", std::env::consts::OS)?;
        writeln!(f, "- **arch**: {}", std::env::consts::ARCH)?;
        writeln!(f)?;

        for section in &self.sections {
            writeln!(f, "## {}", section.title)?;
            writeln!(f)?;
            writeln!(f, "| Tool | Mean | Min | Max | Median | Runs |")?;
            writeln!(f, "|------|-----:|----:|----:|-------:|-----:|")?;
            for r in &section.results {
                writeln!(
                    f,
                    "| {} | {:.1}ms | {:.1}ms | {:.1}ms | {:.1}ms | {} |",
                    r.label,
                    r.stats.mean_ms(),
                    r.stats.min_ms(),
                    r.stats.max_ms(),
                    r.stats.median_ms(),
                    r.stats.runs,
                )?;
            }
            writeln!(f)?;
        }

        writeln!(f, "## Methodology")?;
        writeln!(f)?;
        writeln!(f, "### How to reproduce")?;
        writeln!(f)?;
        writeln!(f, "```sh")?;
        writeln!(f, "# Build lintel in release mode")?;
        writeln!(f, "cargo build --release --package lintel")?;
        writeln!(f)?;
        writeln!(f, "# Install other validator tools")?;
        writeln!(f, "cargo run --release --package lintel-benchmark -- setup")?;
        writeln!(f)?;
        writeln!(f, "# Run all benchmarks")?;
        writeln!(f, "cargo run --release --package lintel-benchmark -- run")?;
        writeln!(f, "```")?;
        writeln!(f)?;
        writeln!(f, "### Commands used")?;
        writeln!(f)?;
        writeln!(f, "| Tool | Single file command | Multi-file command |")?;
        writeln!(f, "|------|--------------------|--------------------|")?;
        writeln!(
            f,
            "| lintel | `lintel check <file>` | `lintel check <dir>` |"
        )?;
        writeln!(
            f,
            "| check-jsonschema | `check-jsonschema --schemafile <url> <file>` | `check-jsonschema --schemafile <url> <file1> <file2> ...` |"
        )?;
        writeln!(
            f,
            "| ajv-cli | `ajv validate -s <url> -d <file>` | `ajv validate -s <schema> -d <file1> -d <file2> ...` |"
        )?;
        writeln!(
            f,
            "| pajv | `pajv validate -s <url> -d <file>` | `pajv validate -s <schema> -d <file1> -d <file2> ...` |"
        )?;
        writeln!(
            f,
            "| jv | `jv <schema> <file>` | `jv <schema> <file1> <file2> ...` |"
        )?;
        writeln!(f)?;
        writeln!(f, "### Configuration")?;
        writeln!(f)?;
        writeln!(
            f,
            "- **lintel binary**: release build (`cargo build --release`)"
        )?;
        writeln!(
            f,
            "- **Warmup runs**: {WARMUP_RUNS} (single/multi), 1 (repo)"
        )?;
        writeln!(f, "- **Timed runs**: {MIN_RUNS} (single/multi), 3-5 (repo)")?;
        writeln!(
            f,
            "- **SchemaStore**: shallow clone of the SchemaStore repo, validating each test file against its corresponding schema"
        )?;
        writeln!(f)?;
        writeln!(f, "### Cache modes")?;
        writeln!(f)?;
        writeln!(
            f,
            "- **warm cache**: All caches (schema + validation result) are populated"
        )?;
        writeln!(
            f,
            "- **--force-validation**: Schema cache is warm, but validation results are recomputed"
        )?;
        writeln!(
            f,
            "- **--force**: All caches bypassed â€” schemas re-fetched, validation recomputed"
        )?;
        writeln!(
            f,
            "- **cold start**: Disk cache directory is deleted before each run"
        )?;
        writeln!(f)?;
        writeln!(f, "### Notes")?;
        writeln!(f)?;
        writeln!(
            f,
            "- Other tools do not have equivalent caching, so they re-fetch and re-validate on every run"
        )?;
        writeln!(
            f,
            "- ajv-cli, pajv, check-jsonschema, and jv require an explicit schema; lintel auto-discovers schemas"
        )?;
        writeln!(
            f,
            "- For the SchemaStore benchmark, each test file is validated against its corresponding schema from `src/schemas/json/`"
        )?;

        println!();
        println!("  Wrote {}", path.display());
        Ok(())
    }
}
